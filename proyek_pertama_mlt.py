# -*- coding: utf-8 -*-
"""Proyek Pertama MLT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KUGOD5Mla_IMpfuvKXqcmvjiLNnotmfm

# **Proyek Machine Learning**

Nama: Melanie Sayyidina Sabrina Refman

## **Import Dataset**
"""

from google.colab import files

# Mengupload file kaggle
files.upload()

# Mengonfigurasi Kaggle API di lingkungan Colab
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

# Mengunduh dataset dari Kaggle menggunakan Kaggle API
!kaggle datasets download -d thedevastator/weather-prediction

from zipfile import ZipFile

# Mengekstrak file zip
file_name = "/content/weather-prediction.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Extraction Completed')

"""## **Import Library**"""

# Import Library
import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout

"""## **Eksplorasi Awal Dataset**"""

# Path dataset
dataset = "weather_prediction_dataset.csv"
df = pd.read_csv(dataset)

print("Dataset Shape:", data.shape)

# Tampilkan beberapa baris awal
print("Preview dataset:")
print(df.head())

# Informasi dataset
print("\nInformasi dataset:")
print(df.info())

"""#### **Memeriksa Data yang Hilang**"""

# Cek missing values
missing_values = df.isnull().sum()
print("\nNilai hilang di setiap kolom:")
print(missing_values)

"""## **Data Preparation**

#### **Data Preprocessing dan Augmentasi**
"""

# Data Transformation
scaler = MinMaxScaler()
data_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

# Assuming 'TG' (mean temperature) as the target variable
X = data_scaled.drop(columns=['BASEL_temp_mean'])
y = data_scaled['BASEL_temp_mean']

# Splitting into Train, Validation, and Test Sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

"""## **Modeling**

#### **Random Forest Regressor:**
"""

# Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

"""#### **Gradient Boosting Regressor:**"""

# Gradient Boosting Regressor
gb_model = GradientBoostingRegressor(random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

"""#### **Recurrent Neural Network (RNN):**"""

# RNN
rnn_model = Sequential([
    LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1), return_sequences=True),
    Dropout(0.2),
    LSTM(50, activation='relu'),
    Dropout(0.2),
    Dense(1)
])
rnn_model.compile(optimizer='adam', loss='mse')

# Reshape data for RNN
X_train_rnn = np.expand_dims(X_train.values, axis=2)
X_val_rnn = np.expand_dims(X_val.values, axis=2)
X_test_rnn = np.expand_dims(X_test.values, axis=2)

# Training the RNN
rnn_model.fit(X_train_rnn, y_train, validation_data=(X_val_rnn, y_val), epochs=50, batch_size=32)
rnn_preds = rnn_model.predict(X_test_rnn)

"""## **Evaluation**"""

# Evaluation function
def evaluate_model(name, y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f"{name} Evaluation:\nMAE: {mae}\nMSE: {mse}\nR^2: {r2}\n")

# Evaluate the models
evaluate_model("Random Forest", y_test, rf_preds)
evaluate_model("Gradient Boosting", y_test, gb_preds)
evaluate_model("RNN", y_test, rnn_preds)

"""## **Testing**"""

# Testing phase (testing the models with unseen data)
print("Testing Random Forest Model:")
rf_test_preds = rf_model.predict(X_test)
evaluate_model("Random Forest Test", y_test, rf_test_preds)

print("Testing Gradient Boosting Model:")
gb_test_preds = gb_model.predict(X_test)
evaluate_model("Gradient Boosting Test", y_test, gb_test_preds)

print("Testing RNN Model:")
rnn_test_preds = rnn_model.predict(X_test_rnn)
evaluate_model("RNN Test", y_test, rnn_test_preds)